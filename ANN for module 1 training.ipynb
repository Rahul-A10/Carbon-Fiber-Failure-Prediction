{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers\n",
    "import random\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r'E:\\Machine learning and AI\\Data for ML\\DATA for ANN.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>t</th>\n",
       "      <th>Ecz</th>\n",
       "      <th>Gyz</th>\n",
       "      <th>Gxz</th>\n",
       "      <th>Tcz</th>\n",
       "      <th>Syz</th>\n",
       "      <th>Sxz</th>\n",
       "      <th>core density</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>137.90</td>\n",
       "      <td>75.842</td>\n",
       "      <td>144.79</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.34474</td>\n",
       "      <td>0.58605</td>\n",
       "      <td>25.630</td>\n",
       "      <td>1.43176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>310.26</td>\n",
       "      <td>111.700</td>\n",
       "      <td>220.63</td>\n",
       "      <td>1.3790</td>\n",
       "      <td>0.55158</td>\n",
       "      <td>0.93079</td>\n",
       "      <td>36.842</td>\n",
       "      <td>1.88024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>482.63</td>\n",
       "      <td>146.170</td>\n",
       "      <td>296.47</td>\n",
       "      <td>2.1374</td>\n",
       "      <td>0.86184</td>\n",
       "      <td>1.37900</td>\n",
       "      <td>48.055</td>\n",
       "      <td>2.32876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>723.95</td>\n",
       "      <td>179.260</td>\n",
       "      <td>379.21</td>\n",
       "      <td>2.8269</td>\n",
       "      <td>1.10320</td>\n",
       "      <td>1.72370</td>\n",
       "      <td>59.268</td>\n",
       "      <td>2.77728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.28</td>\n",
       "      <td>930.79</td>\n",
       "      <td>199.950</td>\n",
       "      <td>448.16</td>\n",
       "      <td>3.8611</td>\n",
       "      <td>1.37900</td>\n",
       "      <td>2.13740</td>\n",
       "      <td>67.278</td>\n",
       "      <td>3.09768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>10</td>\n",
       "      <td>1.68</td>\n",
       "      <td>482.63</td>\n",
       "      <td>146.170</td>\n",
       "      <td>296.47</td>\n",
       "      <td>2.1374</td>\n",
       "      <td>0.86184</td>\n",
       "      <td>1.37900</td>\n",
       "      <td>48.055</td>\n",
       "      <td>2.91991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>10</td>\n",
       "      <td>1.68</td>\n",
       "      <td>723.95</td>\n",
       "      <td>179.260</td>\n",
       "      <td>379.21</td>\n",
       "      <td>2.8269</td>\n",
       "      <td>1.10320</td>\n",
       "      <td>1.72370</td>\n",
       "      <td>59.268</td>\n",
       "      <td>3.03204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>10</td>\n",
       "      <td>1.68</td>\n",
       "      <td>930.79</td>\n",
       "      <td>199.950</td>\n",
       "      <td>448.16</td>\n",
       "      <td>3.8611</td>\n",
       "      <td>1.37900</td>\n",
       "      <td>2.13740</td>\n",
       "      <td>67.278</td>\n",
       "      <td>3.11214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>10</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1379.00</td>\n",
       "      <td>153.730</td>\n",
       "      <td>592.95</td>\n",
       "      <td>5.5158</td>\n",
       "      <td>1.93050</td>\n",
       "      <td>2.96470</td>\n",
       "      <td>86.500</td>\n",
       "      <td>3.30436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>10</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1827.10</td>\n",
       "      <td>299.920</td>\n",
       "      <td>723.95</td>\n",
       "      <td>6.8948</td>\n",
       "      <td>2.41320</td>\n",
       "      <td>3.75760</td>\n",
       "      <td>104.120</td>\n",
       "      <td>3.48056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      d     t      Ecz      Gyz     Gxz     Tcz      Syz      Sxz  \\\n",
       "0    40  0.28   137.90   75.842  144.79  0.6550  0.34474  0.58605   \n",
       "1    40  0.28   310.26  111.700  220.63  1.3790  0.55158  0.93079   \n",
       "2    40  0.28   482.63  146.170  296.47  2.1374  0.86184  1.37900   \n",
       "3    40  0.28   723.95  179.260  379.21  2.8269  1.10320  1.72370   \n",
       "4    40  0.28   930.79  199.950  448.16  3.8611  1.37900  2.13740   \n",
       "..   ..   ...      ...      ...     ...     ...      ...      ...   \n",
       "233  10  1.68   482.63  146.170  296.47  2.1374  0.86184  1.37900   \n",
       "234  10  1.68   723.95  179.260  379.21  2.8269  1.10320  1.72370   \n",
       "235  10  1.68   930.79  199.950  448.16  3.8611  1.37900  2.13740   \n",
       "236  10  1.68  1379.00  153.730  592.95  5.5158  1.93050  2.96470   \n",
       "237  10  1.68  1827.10  299.920  723.95  6.8948  2.41320  3.75760   \n",
       "\n",
       "     core density   weight  \n",
       "0          25.630  1.43176  \n",
       "1          36.842  1.88024  \n",
       "2          48.055  2.32876  \n",
       "3          59.268  2.77728  \n",
       "4          67.278  3.09768  \n",
       "..            ...      ...  \n",
       "233        48.055  2.91991  \n",
       "234        59.268  3.03204  \n",
       "235        67.278  3.11214  \n",
       "236        86.500  3.30436  \n",
       "237       104.120  3.48056  \n",
       "\n",
       "[238 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vari=df.drop(labels=['stress','diflection','WIRF','CIRF','SCIRF','F','U','D','sr.no'],axis=1)\n",
    "vari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WIRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.366400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.243870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.195450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.159650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.140420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.051349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.050026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.049401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.048286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.047633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         WIRF\n",
       "0    0.366400\n",
       "1    0.243870\n",
       "2    0.195450\n",
       "3    0.159650\n",
       "4    0.140420\n",
       "..        ...\n",
       "233  0.051349\n",
       "234  0.050026\n",
       "235  0.049401\n",
       "236  0.048286\n",
       "237  0.047633\n",
       "\n",
       "[238 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans=df.drop(['t','d','Ecz','Gyz','Gxz','Tcz','Syz','Sxz','core density','weight','sr.no','stress','diflection','F','CIRF','SCIRF','U','D'],axis=1)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train1, X_test, y_train1, y_test = train_test_split(vari, ans, test_size=0.15, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train1, y_train1, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>d</td>\n",
       "      <td>171.0</td>\n",
       "      <td>22.239766</td>\n",
       "      <td>10.487856</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.887485</td>\n",
       "      <td>0.489744</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.68000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ecz</td>\n",
       "      <td>171.0</td>\n",
       "      <td>791.289006</td>\n",
       "      <td>553.000016</td>\n",
       "      <td>137.90000</td>\n",
       "      <td>310.260000</td>\n",
       "      <td>723.950000</td>\n",
       "      <td>1379.000000</td>\n",
       "      <td>1827.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gyz</td>\n",
       "      <td>171.0</td>\n",
       "      <td>162.757754</td>\n",
       "      <td>65.732153</td>\n",
       "      <td>75.84200</td>\n",
       "      <td>111.700000</td>\n",
       "      <td>153.730000</td>\n",
       "      <td>199.950000</td>\n",
       "      <td>299.92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gxz</td>\n",
       "      <td>171.0</td>\n",
       "      <td>388.444035</td>\n",
       "      <td>188.940256</td>\n",
       "      <td>144.79000</td>\n",
       "      <td>220.630000</td>\n",
       "      <td>379.210000</td>\n",
       "      <td>592.950000</td>\n",
       "      <td>723.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tcz</td>\n",
       "      <td>171.0</td>\n",
       "      <td>3.185325</td>\n",
       "      <td>2.066808</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>1.379000</td>\n",
       "      <td>2.826900</td>\n",
       "      <td>5.515800</td>\n",
       "      <td>6.89480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Syz</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.181596</td>\n",
       "      <td>0.681629</td>\n",
       "      <td>0.34474</td>\n",
       "      <td>0.551580</td>\n",
       "      <td>1.103200</td>\n",
       "      <td>1.930500</td>\n",
       "      <td>2.41320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sxz</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.857552</td>\n",
       "      <td>1.033071</td>\n",
       "      <td>0.58605</td>\n",
       "      <td>0.930790</td>\n",
       "      <td>1.723700</td>\n",
       "      <td>2.964700</td>\n",
       "      <td>3.75760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>core density</td>\n",
       "      <td>171.0</td>\n",
       "      <td>59.436930</td>\n",
       "      <td>25.392957</td>\n",
       "      <td>25.63000</td>\n",
       "      <td>36.842000</td>\n",
       "      <td>59.268000</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>104.12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>weight</td>\n",
       "      <td>171.0</td>\n",
       "      <td>2.607960</td>\n",
       "      <td>1.132637</td>\n",
       "      <td>0.66286</td>\n",
       "      <td>1.707595</td>\n",
       "      <td>2.430684</td>\n",
       "      <td>3.306275</td>\n",
       "      <td>6.60416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean         std        min         25%  \\\n",
       "d             171.0   22.239766   10.487856   10.00000   12.000000   \n",
       "t             171.0    0.887485    0.489744    0.28000    0.560000   \n",
       "Ecz           171.0  791.289006  553.000016  137.90000  310.260000   \n",
       "Gyz           171.0  162.757754   65.732153   75.84200  111.700000   \n",
       "Gxz           171.0  388.444035  188.940256  144.79000  220.630000   \n",
       "Tcz           171.0    3.185325    2.066808    0.65500    1.379000   \n",
       "Syz           171.0    1.181596    0.681629    0.34474    0.551580   \n",
       "Sxz           171.0    1.857552    1.033071    0.58605    0.930790   \n",
       "core density  171.0   59.436930   25.392957   25.63000   36.842000   \n",
       "weight        171.0    2.607960    1.132637    0.66286    1.707595   \n",
       "\n",
       "                     50%          75%         max  \n",
       "d              18.000000    30.000000    40.00000  \n",
       "t               0.840000     1.120000     1.68000  \n",
       "Ecz           723.950000  1379.000000  1827.10000  \n",
       "Gyz           153.730000   199.950000   299.92000  \n",
       "Gxz           379.210000   592.950000   723.95000  \n",
       "Tcz             2.826900     5.515800     6.89480  \n",
       "Syz             1.103200     1.930500     2.41320  \n",
       "Sxz             1.723700     2.964700     3.75760  \n",
       "core density   59.268000    86.500000   104.12000  \n",
       "weight          2.430684     3.306275     6.60416  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = X_train.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(X_train)\n",
    "normed_test_data = norm(X_test)\n",
    "normed_val_data = norm(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.DataFrame(columns=['activation','seed','neurons per layer','LR','MAE'])\n",
    "acti1=['relu','tanh','softmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range (0,3):    \n",
    "    for b in range (2,61,4):\n",
    "        def build_model(c,d):\n",
    "            tf.random.set_seed(b)\n",
    "            model = keras.Sequential([\n",
    "                layers.Dense(c,activation=acti1[a], input_shape=[len(vari.keys())]),\n",
    "                layers.Dense(c,activation=acti1[a]),\n",
    "                layers.Dense(c,activation=acti1[a]),\n",
    "                layers.Dense(c,activation=acti[a]),\n",
    "                layers.Dense(1)\n",
    "              ])\n",
    "\n",
    "            optimizer = tf.keras.optimizers.RMSprop(1/(10)**d)\n",
    "\n",
    "            model.compile(loss='mse',\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=['mae', 'mse'])\n",
    "            return model\n",
    "\n",
    "        for c in range (32,961,128):\n",
    "            for d in range  (3,5):\n",
    "                model = build_model(c,d)\n",
    "                EPOCHS = 1000\n",
    "             # The patience parameter is the amount of epochs to check for improvement\n",
    "                early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "                early_history = model.fit(normed_train_data, y_train,batch_size=20, \n",
    "                epochs=EPOCHS, validation_data=(normed_val_data,y_val), shuffle=False,verbose=0, \n",
    "                callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n",
    "                loss, mae, mse = model.evaluate(normed_test_data, y_test, verbose=2)\n",
    "                print(\"Testing set Mean Abs Error: {:5.6f} WIRF\".format(mae))\n",
    "                df1 = df1.append({'activation':acti[a],'seed':b,'neurons per layer': c,'LR': d,'MAE':mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('Desktop\\df1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.DataFrame(columns=['activation','seed','neurons per layer','LR','MAE'])\n",
    "acti2=['softplus','elu','sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range (0,3):    \n",
    "    for b in range (2,61,4):\n",
    "        def build_model(c,d):\n",
    "            tf.random.set_seed(b)\n",
    "            model = keras.Sequential([\n",
    "                layers.Dense(c,activation=acti2[a], input_shape=[len(vari.keys())]),\n",
    "                layers.Dense(c,activation=acti2[a]),\n",
    "                layers.Dense(c,activation=acti2[a]),\n",
    "                layers.Dense(c,activation=acti[a]),\n",
    "                layers.Dense(1)\n",
    "              ])\n",
    "\n",
    "            optimizer = tf.keras.optimizers.RMSprop(1/(10)**d)\n",
    "\n",
    "            model.compile(loss='mse',\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=['mae', 'mse'])\n",
    "            return model\n",
    "\n",
    "        for c in range (32,961,128):\n",
    "            for d in range  (3,5):\n",
    "                model = build_model(c,d)\n",
    "                EPOCHS = 1000\n",
    "             # The patience parameter is the amount of epochs to check for improvement\n",
    "                early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "                early_history = model.fit(normed_train_data, y_train,batch_size=20, \n",
    "                epochs=EPOCHS, validation_data=(normed_val_data,y_val), shuffle=False,verbose=0, \n",
    "                callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n",
    "                loss, mae, mse = model.evaluate(normed_test_data, y_test, verbose=2)\n",
    "                print(\"Testing set Mean Abs Error: {:5.6f} WIRF\".format(mae))\n",
    "                df2 = df2.append({'activation':acti[a],'seed':b,'neurons per layer': c,'LR': d,'MAE':mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel('Desktop\\df2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= pd.DataFrame(columns=['activation','seed','neurons per layer','LR','MAE'])\n",
    "acti3=['selu','softsign','hard_sigmoid','exponential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range (0,4):    \n",
    "    for b in range (2,61,4):\n",
    "        def build_model(c,d):\n",
    "            tf.random.set_seed(b)\n",
    "            model = keras.Sequential([\n",
    "                layers.Dense(c,activation=acti3[a], input_shape=[len(vari.keys())]),\n",
    "                layers.Dense(c,activation=acti3[a]),\n",
    "                layers.Dense(c,activation=acti3[a]),\n",
    "                layers.Dense(c,activation=acti[a]),\n",
    "                layers.Dense(1)\n",
    "              ])\n",
    "\n",
    "            optimizer = tf.keras.optimizers.RMSprop(1/(10)**d)\n",
    "\n",
    "            model.compile(loss='mse',\n",
    "                            optimizer=optimizer,\n",
    "                            metrics=['mae', 'mse'])\n",
    "            return model\n",
    "\n",
    "        for c in range (32,961,128):\n",
    "            for d in range  (3,5):\n",
    "                model = build_model(c,d)\n",
    "                EPOCHS = 1000\n",
    "             # The patience parameter is the amount of epochs to check for improvement\n",
    "                early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "                early_history = model.fit(normed_train_data, y_train,batch_size=20, \n",
    "                epochs=EPOCHS, validation_data=(normed_val_data,y_val), shuffle=False,verbose=0, \n",
    "                callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n",
    "                loss, mae, mse = model.evaluate(normed_test_data, y_test, verbose=2)\n",
    "                print(\"Testing set Mean Abs Error: {:5.6f} WIRF\".format(mae))\n",
    "                df3 = df3.append({'activation':acti[a],'seed':b,'neurons per layer': c,'LR': d,'MAE':mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_excel('Desktop\\df3.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
